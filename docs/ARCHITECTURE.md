# Architecture Documentation

Technical architecture of the Monobase Infrastructure template.

## Table of Contents

1. [Overview](#overview)
2. [System Architecture](#system-architecture)
3. [Gateway Architecture](#gateway-architecture)
4. [Storage Architecture](#storage-architecture)
5. [Security Architecture](#security-architecture)
6. [Backup Architecture](#backup-architecture)
7. [Monitoring Architecture](#monitoring-architecture)

---

## Overview

### Design Principles

1. **No Overengineering** - Simple, proven technologies for <500 users
2. **Security by Default** - Zero-trust, encryption everywhere
3. **Fork-Based Workflow** - Reusable template, client-specific configuration
4. **Cloud-Native** - Kubernetes-native, CNCF projects preferred
5. **Cost-Effective** - Shared infrastructure, optional components

### High-Level System Architecture

```mermaid
graph TB
    subgraph "Internet"
        Users[ğŸ‘¥ Users/Clients]
    end
    
    subgraph "Kubernetes Cluster"
        subgraph "gateway-system namespace"
            Gateway[ğŸŒ Envoy Gateway<br/>shared-gateway<br/>2 replicas]
        end
        
        subgraph "client-a-prod namespace"
            HapiHub1[âš•ï¸ HapiHub API<br/>3 replicas]
            MyCureApp1[ğŸ“± MyCureApp<br/>2 replicas]
            Syncd1[ğŸ”„ Syncd<br/>2 replicas]
            MongoDB1[(ğŸ—„ï¸ MongoDB<br/>3-node replica)]
            MinIO1[(ğŸ“¦ MinIO<br/>6-node distributed)]
        end
        
        subgraph "client-b-prod namespace"
            HapiHub2[âš•ï¸ HapiHub API]
            Apps2[ğŸ“± Apps...]
        end
        
        subgraph "Infrastructure"
            Longhorn[ğŸ’¾ Longhorn Storage]
            ArgoCD[ğŸ”„ ArgoCD GitOps]
            ExtSecrets[ğŸ” External Secrets]
            CertMgr[ğŸ”’ cert-manager]
            Velero[ğŸ’¼ Velero Backups]
        end
    end
    
    subgraph "Cloud Provider KMS"
        KMS[ğŸ”‘ AWS Secrets Manager<br/>Azure Key Vault<br/>GCP Secret Manager]
    end
    
    Users -->|HTTPS| Gateway
    Gateway -->|HTTPRoute| HapiHub1
    Gateway -->|HTTPRoute| MyCureApp1
    Gateway -->|HTTPRoute| HapiHub2
    HapiHub1 --> MongoDB1
    HapiHub1 --> MinIO1
    Syncd1 --> MongoDB1
    ArgoCD -.->|manages| HapiHub1
    ArgoCD -.->|manages| MyCureApp1
    ExtSecrets -->|fetches| KMS
    ExtSecrets -.->|injects| HapiHub1
    Velero -.->|backups| MongoDB1
    Longhorn -.->|provides storage| MongoDB1
```

### Technology Stack

**Core (Always Deployed):**
- Kubernetes 1.27+ (EKS, AKS, GKE, or self-hosted)
- Envoy Gateway (Gateway API)
- Longhorn (distributed storage)
- ArgoCD (GitOps)
- External Secrets Operator (KMS integration)
- cert-manager (TLS automation)

**Applications:**
- HapiHub (API backend)
- MyCureApp (Vue.js frontend)
- MongoDB 7.x (primary database)

**Optional:**
- Syncd (real-time sync)
- MinIO (self-hosted S3)
- Typesense (search engine)
- Velero (Kubernetes backups)
- Prometheus + Grafana (monitoring)

**NOT Included (Deliberately):**
- âŒ Service Mesh (Istio/Linkerd) - Overkill for 3 services
- âŒ Self-hosted Vault - Use cloud KMS instead
- âŒ Rook-Ceph - Longhorn + MinIO simpler

---

## System Architecture

### Request Flow Diagram

```mermaid
sequenceDiagram
    participant U as ğŸ‘¤ User
    participant DNS as ğŸŒ DNS
    participant LB as âš–ï¸ LoadBalancer
    participant GW as ğŸšª Envoy Gateway
    participant API as âš•ï¸ HapiHub API
    participant DB as ğŸ—„ï¸ MongoDB
    participant S3 as ğŸ“¦ MinIO/S3
    
    U->>DNS: api.client-a.com
    DNS-->>U: LoadBalancer IP
    U->>LB: HTTPS Request
    LB->>GW: Forward to Gateway
    Note over GW: Rate Limiting<br/>Security Headers<br/>TLS Termination
    GW->>GW: Match HTTPRoute<br/>(api.client-a.com)
    GW->>API: Route to HapiHub<br/>(client-a-prod ns)
    API->>DB: Query Data
    DB-->>API: Response
    API->>S3: Fetch File
    S3-->>API: File Data
    API-->>GW: JSON Response
    GW-->>LB: Response
    LB-->>U: HTTPS Response
```

### Multi-Tenant Architecture

```mermaid
graph TB
    subgraph "Single Kubernetes Cluster"
        subgraph "Shared Gateway"
            GW[Envoy Gateway<br/>LoadBalancer IP: X.X.X.X]
        end
        
        subgraph "client-a-prod namespace"
            R1[HTTPRoute<br/>api.client-a.com]
            H1[HapiHub-A]
            DB1[(MongoDB-A)]
        end
        
        subgraph "client-b-prod namespace"
            R2[HTTPRoute<br/>api.client-b.com]
            H2[HapiHub-B]
            DB2[(MongoDB-B)]
        end
        
        subgraph "client-c-staging namespace"
            R3[HTTPRoute<br/>api.client-c-staging.com]
            H3[HapiHub-C]
            DB3[(MongoDB-C)]
        end
        
        subgraph "Infrastructure (Shared)"
            NP[NetworkPolicies<br/>Namespace Isolation]
            Storage[Longhorn<br/>Distributed Storage]
        end
    end
    
    GW --> R1
    GW --> R2
    GW --> R3
    R1 --> H1
    R2 --> H2
    R3 --> H3
    H1 --> DB1
    H2 --> DB2
    H3 --> DB3
    NP -.->|isolates| client-a-prod
    NP -.->|isolates| client-b-prod
    NP -.->|isolates| client-c-staging
    Storage -.->|provides PVCs| DB1
    Storage -.->|provides PVCs| DB2
    Storage -.->|provides PVCs| DB3
```

### Component Diagram

```
                    Internet / DNS
                          |
                   [LoadBalancer IP]
                          |
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚    gateway-system namespace       â”‚
        â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
        â”‚  â”‚   Shared Envoy Gateway       â”‚ â”‚
        â”‚  â”‚   - HTTPS listener (443)     â”‚ â”‚
        â”‚  â”‚   - HA: 2 replicas           â”‚ â”‚
        â”‚  â”‚   - Rate limiting            â”‚ â”‚
        â”‚  â”‚   - Security headers         â”‚ â”‚
        â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚   myclient-prod namespace         â”‚
        â”‚                                   â”‚
        â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
        â”‚  â”‚ HTTPRoutes (per service)   â”‚  â”‚
        â”‚  â”‚ - api.myclient.com         â”‚  â”‚
        â”‚  â”‚ - app.myclient.com         â”‚  â”‚
        â”‚  â”‚ - sync.myclient.com        â”‚  â”‚
        â”‚  â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
        â”‚        â”‚                          â”‚
        â”‚  â”Œâ”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”â”‚
        â”‚  â”‚            â”‚        â”‚        â”‚â”‚
        â”‚ â”Œâ–¼â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â–¼â”€â”€â”€â”€â” â”Œâ–¼â”€â”€â”€â”€â”€â”€â” â”‚â”‚
        â”‚ â”‚HapiHubâ”‚ â”‚ Syncd â”‚ â”‚MyCure â”‚ â”‚â”‚
        â”‚ â”‚ App   â”‚ â”‚       â”‚ â”‚ App   â”‚ â”‚â”‚
        â”‚ â”‚2-3 repâ”‚ â”‚2 rep  â”‚ â”‚2 rep  â”‚ â”‚â”‚
        â”‚ â””â”€â”€â”€â”¬â”€â”€â”€â”˜ â””â”€â”€â”€â”¬â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚â”‚
        â”‚     â”‚         â”‚                â”‚â”‚
        â”‚  â”Œâ”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”             â”‚â”‚
        â”‚  â”‚               â”‚             â”‚â”‚
        â”‚ â”Œâ–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚â”‚
        â”‚ â”‚  MongoDB    â”‚ â”‚  MinIO   â”‚  â”‚â”‚
        â”‚ â”‚  Replica Setâ”‚ â”‚ Distrib. â”‚  â”‚â”‚
        â”‚ â”‚  3 nodes    â”‚ â”‚ 6 nodes  â”‚  â”‚â”‚
        â”‚ â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜  â”‚â”‚
        â”‚        â”‚             â”‚         â”‚â”‚
        â”‚  â”Œâ”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â” â”‚â”‚
        â”‚  â”‚   Longhorn Storage       â”‚ â”‚â”‚
        â”‚  â”‚   - 3x replication       â”‚ â”‚â”‚
        â”‚  â”‚   - Snapshots            â”‚ â”‚â”‚
        â”‚  â”‚   - Encryption           â”‚ â”‚â”‚
        â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Data Flow

**1. User Request â†’ HapiHub API:**
```
Browser â†’ DNS â†’ LoadBalancer â†’ Gateway (443) 
  â†’ HTTPRoute (api.myclient.com) â†’ HapiHub Service (7500) 
  â†’ HapiHub Pod â†’ MongoDB (27017)
```

**2. User Request â†’ Frontend:**
```
Browser â†’ DNS â†’ LoadBalancer â†’ Gateway (443)
  â†’ HTTPRoute (app.myclient.com) â†’ MyCureApp Service (80)
  â†’ MyCureApp Pod (nginx serving static files)
```

**3. File Upload Flow:**
```
Client â†’ HapiHub API â†’ MinIO S3 API (9000)
  â†’ Longhorn PVC â†’ Distributed storage across nodes
```

**4. File Download Flow:**
```
Client â†’ HapiHub (generates presigned URL)
  â†’ Client downloads directly from MinIO via Gateway
  â†’ HTTPRoute (storage.myclient.com) â†’ MinIO (9000)
```

---

## Gateway Architecture

### Shared Gateway Strategy

**Key Decision: 1 Gateway + Dynamic HTTPRoutes**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  gateway-system namespace (shared) â”‚
â”‚                                     â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚   Shared Gateway              â”‚ â”‚
â”‚  â”‚   - Single HTTPS listener     â”‚ â”‚
â”‚  â”‚   - Wildcard: *.myclient.com  â”‚ â”‚
â”‚  â”‚   - HA: 2 Envoy replicas      â”‚ â”‚
â”‚  â”‚   - Single LoadBalancer IP    â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â”‚ References
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚          â”‚          â”‚
â”Œâ”€â”€â”€â–¼â”€â”€â”€â”€â” â”Œâ”€â”€â–¼â”€â”€â”€â”€â”€â” â”Œâ”€â–¼â”€â”€â”€â”€â”€â”€â”
â”‚Client Aâ”‚ â”‚Client Bâ”‚ â”‚Client Câ”‚
â”‚HTTPRtesâ”‚ â”‚HTTPRtesâ”‚ â”‚HTTPRtesâ”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Benefits:**
- âœ… **Zero-downtime client onboarding** - HTTPRoutes added dynamically
- âœ… **Single LoadBalancer IP** - Cost-effective
- âœ… **Independent routing** - Each client controls their routes
- âœ… **Flexible hostnames** - Any domain per service

**HTTPRoute Pattern:**
```yaml
apiVersion: gateway.networking.k8s.io/v1
kind: HTTPRoute
spec:
  parentRefs:
    - name: shared-gateway  # References shared Gateway
      namespace: gateway-system
  hostnames:
    - api.client.com       # Client-specific domain
  rules:
    - backendRefs:
        - name: hapihub
          port: 7500
```

---

## Storage Architecture

### Longhorn Distributed Block Storage

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         Longhorn Storage Cluster        â”‚
â”‚                                         â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚ Node 1 â”‚  â”‚ Node 2 â”‚  â”‚ Node 3 â”‚   â”‚
â”‚  â”‚        â”‚  â”‚        â”‚  â”‚        â”‚   â”‚
â”‚  â”‚ Replicaâ”‚  â”‚ Replicaâ”‚  â”‚ Replicaâ”‚   â”‚
â”‚  â”‚   A    â”‚  â”‚   A    â”‚  â”‚   A    â”‚   â”‚
â”‚  â”‚ Replicaâ”‚  â”‚ Replicaâ”‚  â”‚ Replicaâ”‚   â”‚
â”‚  â”‚   B    â”‚  â”‚   B    â”‚  â”‚   B    â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                         â”‚
â”‚  Data replicated 3x across nodes       â”‚
â”‚  Can lose 2 nodes without data loss    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â–²
         â”‚ iSCSI / NVMe
         â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  StatefulSets    â”‚
â”‚  - MongoDB       â”‚
â”‚  - MinIO         â”‚
â”‚  - Typesense     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Features:**
- **3-way replication** - Data on 3 nodes
- **Automatic failover** - Rebuilds replicas on node failure
- **Snapshots** - Hourly local snapshots
- **Backups** - Daily S3 backups
- **Encryption** - dm-crypt volume encryption
- **Expansion** - Online volume resize

### MinIO Distributed Storage (Optional)

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚     MinIO Erasure Coding (EC:2)         â”‚
â”‚                                          â”‚
â”‚  6 Nodes Ã— 250Gi = 1.5TB raw            â”‚
â”‚  4 data + 2 parity = ~1TB usable (66%)  â”‚
â”‚                                          â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”            â”‚
â”‚  â”‚Data 1â”‚ â”‚Data 2â”‚ â”‚Data 3â”‚            â”‚
â”‚  â”‚250Gi â”‚ â”‚250Gi â”‚ â”‚250Gi â”‚            â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”˜            â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”            â”‚
â”‚  â”‚Data 4â”‚ â”‚Parityâ”‚ â”‚Parityâ”‚            â”‚
â”‚  â”‚250Gi â”‚ â”‚ 1    â”‚ â”‚  2   â”‚            â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”˜            â”‚
â”‚                                          â”‚
â”‚  Can lose 2 nodes without data loss     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Why MinIO:**
- S3-compatible API
- No egress fees (self-hosted)
- <1TB data (cost-effective)
- Full control

**Why External S3:**
- >1TB data (scale better)
- Global CDN integration
- Managed service
- Built-in redundancy

---

## Security Architecture

### Zero-Trust Network Model

```
Default: DENY ALL
    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  All traffic blocked by default â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â†“
Explicit ALLOW rules:
    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ âœ… Gateway â†’ Apps               â”‚
â”‚ âœ… Apps â†’ MongoDB               â”‚
â”‚ âœ… Apps â†’ Storage               â”‚
â”‚ âœ… Apps â†’ Internet (HTTPS)      â”‚
â”‚ âŒ Cross-namespace (blocked)    â”‚
â”‚ âŒ Direct pod access (blocked)  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Defense in Depth

**Layer 1: Network (NetworkPolicies)**
- Default deny all traffic
- Explicit allow rules only
- Cross-namespace isolation
- DNS and K8s API allowed

**Layer 2: Pod (Pod Security Standards)**
- Non-root containers
- No privilege escalation
- Drop ALL capabilities
- Read-only root filesystem
- seccomp profile enforced

**Layer 3: Application (RBAC)**
- Dedicated service accounts
- Least-privilege roles
- No default SA usage
- Namespace-scoped permissions

**Layer 4: Data (Encryption)**
- At rest: Longhorn + MongoDB encryption
- In transit: TLS everywhere (cert-manager)
- Backups: S3 + KMS encryption

**Layer 5: Access (External Secrets)**
- Secrets never in Git
- KMS integration (AWS/Azure/GCP)
- Automatic rotation
- Audit logging

---

## Backup Architecture

### 3-Tier Backup Strategy

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Tier 1: Hourly Snapshots (Fast)        â”‚
â”‚  - Storage: Local (Longhorn nodes)      â”‚
â”‚  - Retention: 72 hours                  â”‚
â”‚  - Recovery: ~5 minutes                 â”‚
â”‚  - Use: Quick rollback, recent issues   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
              â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Tier 2: Daily Backups (Medium)         â”‚
â”‚  - Storage: S3 (off-cluster)            â”‚
â”‚  - Retention: 30 days                   â”‚
â”‚  - Recovery: ~1 hour                    â”‚
â”‚  - Use: Last month recovery             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
              â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Tier 3: Weekly Archive (Long-term)     â”‚
â”‚  - Storage: S3 Glacier (cold)           â”‚
â”‚  - Retention: 90+ days (HIPAA)          â”‚
â”‚  - Recovery: ~4 hours                   â”‚
â”‚  - Use: Compliance, disaster recovery   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Backup Methods:**

1. **Longhorn Snapshots** - Volume-level, COW snapshots
2. **Velero Backups** - Kubernetes-native, application-aware
3. **MongoDB dumps** - Application-level (optional)

**Recovery Time Objectives (RTO):**
- Tier 1: 5 minutes
- Tier 2: 1 hour
- Tier 3: 4 hours

**Recovery Point Objectives (RPO):**
- Tier 1: 1 hour (max data loss)
- Tier 2: 24 hours
- Tier 3: 1 week

---

## Monitoring Architecture

### Optional Monitoring Stack

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚           Applications                  â”‚
â”‚  HapiHub, Syncd, MyCureApp             â”‚
â”‚  /metrics endpoints                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â”‚ scrape
        â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚  Prometheus   â”‚
        â”‚  - 15d retain â”‚
        â”‚  - 50Gi PVC   â”‚
        â”‚  - HA: 2 rep  â”‚
        â””â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”˜
            â”‚       â”‚
    â”Œâ”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â” â”Œâ”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚ Grafana  â”‚ â”‚ Alertmanager â”‚
    â”‚Dashboard â”‚ â”‚ Slack/PagerD â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**When to Enable:**
- Production environments
- >100 active users
- After baseline established
- Business-critical services

**Resource Overhead:**
- ~3-5% additional CPU/memory
- ~60Gi additional storage
- Worth it for production visibility

---

## High Availability

### Component HA Strategy

| Component | Replicas | Strategy | Downtime on Failure |
|-----------|----------|----------|---------------------|
| HapiHub | 2-3 | Rolling update + PDB | 0s (other pods serve) |
| MyCureApp | 2 | Rolling update + PDB | 0s |
| Syncd | 2 | Rolling update + PDB | 0s |
| MongoDB | 3 | Replica set | <30s (auto-failover) |
| MinIO | 6 | Erasure coding | 0s (2 node tolerance) |
| Envoy Gateway | 2 | Anti-affinity | <1s (pod swap) |
| Longhorn | 3 | Volume replication | 0s (auto-rebuild) |

### Update Strategy

**Zero-Downtime Updates:**
1. Rolling update with `maxSurge: 1`, `maxUnavailable: 0`
2. PodDisruptionBudget ensures `minAvailable: 1`
3. Health checks prevent unhealthy pod traffic
4. Gateway routes to healthy pods only

**Example Update:**
```
Before: Pod A (v1), Pod B (v1)
Step 1: Pod A (v1), Pod B (v1), Pod C (v2) â† new pod
Step 2: Pod A terminating, Pod B (v1), Pod C (v2)
Step 3: Pod B (v1), Pod C (v2), Pod D (v2) â† new pod
Step 4: Pod B terminating, Pod C (v2), Pod D (v2)
After: Pod C (v2), Pod D (v2) â† 100% v2, zero downtime
```

---

## Namespace Architecture

### Per-Client + Per-Environment Isolation

```
Cluster
â”œâ”€â”€ gateway-system (shared)
â”‚   â””â”€â”€ shared-gateway (1 Gateway, HA: 2 replicas)
â”‚
â”œâ”€â”€ longhorn-system (shared)
â”‚   â””â”€â”€ Longhorn components
â”‚
â”œâ”€â”€ external-secrets-system (shared)
â”‚   â””â”€â”€ External Secrets Operator
â”‚
â”œâ”€â”€ velero (shared)
â”‚   â””â”€â”€ Velero backup controller
â”‚
â”œâ”€â”€ argocd (shared)
â”‚   â””â”€â”€ ArgoCD components
â”‚
â”œâ”€â”€ monitoring (shared, optional)
â”‚   â””â”€â”€ Prometheus + Grafana
â”‚
â”œâ”€â”€ client-a-prod
â”‚   â”œâ”€â”€ hapihub, syncd, mycureapp
â”‚   â”œâ”€â”€ mongodb, minio, typesense
â”‚   â””â”€â”€ HTTPRoutes â†’ shared-gateway
â”‚
â”œâ”€â”€ client-a-staging
â”‚   â”œâ”€â”€ hapihub, mycureapp
â”‚   â”œâ”€â”€ mongodb
â”‚   â””â”€â”€ HTTPRoutes â†’ shared-gateway
â”‚
â””â”€â”€ client-b-prod
    â”œâ”€â”€ hapihub, syncd, mycureapp
    â”œâ”€â”€ mongodb, minio
    â””â”€â”€ HTTPRoutes â†’ shared-gateway
```

**Benefits:**
- **Isolation** - Each client in separate namespace
- **Security** - NetworkPolicies prevent cross-namespace traffic
- **Resource Control** - ResourceQuotas per namespace
- **Independent Scaling** - Scale clients independently
- **Cost Allocation** - Track resources per client

---

## Security Zones

### Zone Model

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  DMZ (Public Internet)                  â”‚
â”‚  - Gateway LoadBalancer (public IP)     â”‚
â”‚  - TLS termination                      â”‚
â”‚  - Rate limiting                        â”‚
â”‚  - DDoS protection                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â”‚ HTTPS only
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Application Zone                       â”‚
â”‚  - HapiHub, Syncd, MyCureApp           â”‚
â”‚  - NetworkPolicy: allow from Gateway    â”‚
â”‚  - Pod Security: restricted             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â”‚ Authenticated connections
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Data Zone                              â”‚
â”‚  - MongoDB (TLS + auth)                 â”‚
â”‚  - MinIO (IAM auth)                     â”‚
â”‚  - NetworkPolicy: allow from apps only  â”‚
â”‚  - Encryption at rest                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## Disaster Recovery

### RTO/RPO Targets

| Scenario | RTO | RPO | Recovery Method |
|----------|-----|-----|-----------------|
| Pod failure | 0s | 0 | Auto-restart + HA |
| Node failure | <30s | 0 | Pod rescheduling |
| AZ failure | <5min | 1h | Longhorn snapshot restore |
| Database corruption | <1h | 24h | Velero daily backup |
| Cluster failure | <4h | 1w | Velero weekly + new cluster |
| Region failure | <8h | 1w | Cross-region backup restore |

### Failure Scenarios

**1. Single Pod Failure:**
- **Detection:** Health check fails
- **Action:** Kubernetes restarts pod automatically
- **Impact:** None (other replicas serve traffic)
- **RTO:** <30s

**2. Node Failure:**
- **Detection:** Node goes NotReady
- **Action:** Pods rescheduled to healthy nodes
- **Impact:** Brief degradation if node had replicas
- **RTO:** 1-5 minutes
- **Longhorn:** Rebuilds volume replicas automatically

**3. MongoDB Replica Failure:**
- **Detection:** Replica set monitoring
- **Action:** Automatic failover to secondary
- **Impact:** <30s connection interruption
- **RTO:** <30s

**4. Complete Cluster Failure:**
- **Detection:** All nodes down
- **Action:** Restore to new cluster from Velero backup
- **Impact:** Full outage during restore
- **RTO:** 2-4 hours
- **RPO:** Last successful backup (24h max)

---

## Scalability

### Horizontal Scaling

**Application Pods (via HPA):**
```
Traffic increases â†’ CPU >70% â†’ HPA adds pods
  â†’ More replicas â†’ CPU normalizes â†’ Stable
```

**Storage (via Volume Expansion):**
```
Storage fills â†’ Expand PVC â†’ Longhorn expands volume
  â†’ No downtime â†’ More space available
```

### Scaling Limits (Current Architecture)

| Component | Max Replicas | Bottleneck |
|-----------|--------------|------------|
| HapiHub | 10 | MongoDB connections |
| MyCureApp | 20 | None (stateless) |
| Syncd | 5 | WebSocket connections |
| MongoDB | 5 | Replication overhead |
| MinIO | 16 | Erasure coding limit |

**For >500 users:**
- Add MongoDB sharding
- Add read replicas
- Consider external S3
- Add caching layer (Redis)

---

## Summary

The Monobase Infrastructure template provides:

âœ… **Modern Architecture** - Gateway API, GitOps, cloud-native
âœ… **High Availability** - Multi-replica, auto-failover, zero-downtime
âœ… **Security** - Zero-trust, encryption everywhere
âœ… **Disaster Recovery** - 3-tier backups, tested procedures
âœ… **Scalability** - HPA, storage expansion, multi-tenant
âœ… **Observability** - Metrics, logs, alerts, dashboards

**Target:** <500 users, <1TB data per client
**Architecture:** Simple, proven, production-ready

For detailed operational procedures, see:
- [DEPLOYMENT.md](DEPLOYMENT.md) - Deployment steps
- [STORAGE.md](STORAGE.md) - Storage operations
- [BACKUP-RECOVERY.md](BACKUP-RECOVERY.md) - DR procedures
- [SCALING-GUIDE.md](SCALING-GUIDE.md) - Scaling guide
